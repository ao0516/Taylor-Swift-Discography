---
title: "Taylor Swift"
output: html_document
date: "2024-01-25"
---


```{r setup, include = FALSE}

library(tidyverse)
library(taylor)

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```


There are three main data sets. The first is `taylor_album_songs`, which includes lyrics and audio features from the Spotify API for all songs on Taylor's official studio albums. Notably this excludes singles released separately from an album (e.g., *Only the Young*, *Christmas Tree Farm*, etc.), and non-Taylor-owned albums that have a Taylor-owned alternative (e.g., *Fearless* is excluded in favor of *Fearless (Taylor's Version)*). We stan artists owning their own songs.

```{r album-songs}
taylor_albulm_songs <- taylor_album_songs
```

You can access Taylor's entire discography with `taylor_all_songs`. This includes all of the songs in `taylor_album_songs` plus EPs, individual singles, and the original versions of albums that have been re-released as *Taylor's Version*.

```{r all-songs}
taylor_all_songs <- taylor_all_songs
```

Finally, there is a small data set, `taylor_albums`, summarizing Taylor's album release history.

```{r albums}
taylor_albums <- taylor_albums
```

```{r}

# Set up Spotify API access
client_id <- 'b5af36ff5bf1490b8e41060102108c5d'
client_secret <- '8b58d77e04024dfb92b775a989872556'

token <- httr::POST(
  url = "https://accounts.spotify.com/api/token",
  body = list(grant_type = "client_credentials"),
  authenticate(client_id, client_secret),
  encode = "form"
) |> httr::content("parsed")

artist_id = '06HL4z0CvFAxyc27GXpf02'  # Taylor Swift's Spotify artist ID



```

```{r}
# Install and load required packages
library(httr)
library(dplyr)


# Set up Spotify API access
client_id <- 'b5af36ff5bf1490b8e41060102108c5d'
client_secret <- 

# Authenticate with Spotify API
token <- httr::POST(
  url = "https://accounts.spotify.com/api/token",
  body = list(
    grant_type = "client_credentials"
  ),
  authenticate(client_id, client_secret),
  encode = "form"
) |> httr::content("parsed")

# Get Taylor Swift's discography
artist_id <- '06HL4z0CvFAxyc27GXpf02'  # Taylor Swift's Spotify artist ID

albums <- httr::GET(
  url = paste0("https://api.spotify.com/v1/artists/", artist_id, "/albums"),
  add_headers(Authorization = paste0("Bearer ", token$access_token))
) |> httr::content("parsed")

# Extract track IDs
track_ids <- sapply(albums$items, function(album) album$uri)

# Get audio features for each track
audio_features <- lapply(track_ids, function(track_id) {
  httr::GET(
    url = paste0("https://api.spotify.com/v1/audio-features/", URLencode(track_id)),
    add_headers(Authorization = paste0("Bearer ", token$access_token))
  ) |> httr::content("parsed")
})

# Extract popularity scores
popularity_scores <- sapply(audio_features, function(features) features$popularity)

```


```{r}

# Manually input the data for the new column
new_data <- c("120681144", "177476212", "201819648","38006696", "393555192", "27152957","30582153", "32159952", "111944757","41444442", "307657056", "46882871","32245922", "23516670", "30572544","114156809", "112324751", "839744760","48099348", "107857315", "607923068","67075537", "30676668", "45283757","68235800", "52528575", "38744030","26360809", "24913357", "22122687","26726100", "16360926", "13485429","14594796", "242744567", "90429706","642874800", "80554113", "85751097","554449538", "60331549", "51745577","64918203", "372522117", "99531508","47007427", "40393013", "50309638","50849541", "46847438", "36709406","33064626", "63990782", "47992191","104232029", "338943982", "54201297","71648351", "64098942", "50410737","216622266", "176533939", "375695596","140422062", "138694598", "222507257","149240409", "83127466", "755265586","185784783", "51036807", "100252218","120077288", "97483745", "70337971","42824112", "25172244", "137598364","96288640", "154712290", "84439221","86658091", "78879153", "77593542","46524427", "210044452", "102713874","39370922", "62365463", "62246155","96599305", "44063949", "33190443","70412269", "67928411", "209477724","69169962", "73751551", "68510110","60185233", "246645932", "54474537","784032106", "241173542", "372594988","61283829", "640769212", "56534725","65603684", "53575303", "39204272","43261910", "267564922", "42901025","123730013", "31632535", "41752633","22737389", "16410445", "17361810","23578304", "112739959", "255300904","100677120", "296807428", "233770103","236644107", "83996319", "281840712","81319480", "100640319", "77891461","86945215", "70397598", "132932137","54026514", "91309204", "64540303","100182544", "53340003", "47957284","39802175", "129923150", "195924465","109649205", "175985002", "194926834","84654003", "129930225", "155705618","756279728", "239916921", "1708424142","1126140383", "315910730", "215419525","1314935590", "149014116", "567280513","911638013", "165093811", "105668885","131308107", "190696276", "145464422","138988778", "268717421", "79944241","111645621", "135303977", "92164969","69901392", "75220894", "61153405","58289749", "637705307", "52435052","218504402", "54175738", "67558793","53249147", "53636077", "80990224","182041125", "131080271", "192284098","82161697", "278728794", "44568311","0", "641217600", "462393157","403266217", "974677460", "905588449","1065314038", "164867171", "551200809","591307342", "243791713", "227813502","286952177", "202576744", "366811972","177239723", "316678932", "1702854354","1216532258", "674515918", "347936552","251389518", "320922544", "586467395","298413464", "263228708", "298982938","134128730", "209395928", "861573553","344877626", "821623783", "121892420","331291433", "517471858", "1134549436","327256102", "692171271", "421587992","374276274", "279820925", "951233896","347716932", "348053926", "326442749","195226335", "169440299", "317284578","190318606", "169945233", "136746855","761640338", "549133358", "264011028","242750122", "268716361", "252268798","170449092", "157984690", "164324824","198072621", "168398970", "179014975","185623035", "112206035", "194506016","287073192", "97565857", "644669609","416296179", "1383375573", "400157718","508906632", "588591167", "275878118","352373319", "468159365", "245634517","664386951", "248101984", "303420920","251709137", "163733564", "165266287","138928261", "110633604", "239775114","113609367", "155887518", "150209125","0", "0", "79199767", "131773671", "29878596","7090920", "11455602", "5465924","6517594", "5872393", "0","0", "0", "0","0", "0", "314448827","0", "0", "0","0", "0", "0","0", "0", "0","0", "0", "0","0", "0", "0","0", "0", "0","0", "0", "0","0", "0", "0","0", "0", "0","0", "0") 

# Add the new column directly to the existing data frame
taylor_all_songs$Streams <- new_data

taylor_all_songs$Streams <- as.numeric(taylor_all_songs$Streams)


```

```{r}
# Exclude columns with list type
columns_to_exclude <- sapply(taylor_all_songs, is.list)
taylor_all_songs_no_lists <- taylor_all_songs[, !columns_to_exclude]

# Write CSV without row names
write.csv(taylor_all_songs_no_lists, 'taylor_swift_discography.csv', row.names = FALSE)

```


## Summary Statistics
```{r}
summary(taylor_all_songs)
```

## Stream normality
```{r}
library(e1071)
library(ggplot2)
library(caret)

# Select relevant columns for the model
selected_features <- c("album_name", "track_number", "track_name", "danceability", "energy", "key", "loudness", "mode", "speechiness", "acousticness", "instrumentalness", "liveness", "valence", "tempo", "time_signature", "duration_ms", "explicit", "key_name", "mode_name", "key_mode", "Streams")

# Create a data frame with selected features and the target variable
model_data <- taylor_all_songs %>%
  select(Streams, all_of(selected_features)) %>%
  na.omit()  # Remove rows with missing values

set.seed(123)
train_index <- createDataPartition(model_data$Streams, p = 0.8, list = FALSE)
train_data <- model_data[train_index, ]
test_data <- model_data[-train_index, ]
# Ensure levels of categorical variables are consistent
categorical_columns <- c("album_name", "track_name", "key_name", "mode_name")
for (col in categorical_columns) {
  levels_train <- levels(train_data[[col]])
  test_data[[col]] <- factor(test_data[[col]], levels = levels_train)
}

# Plot a histogram
ggplot(train_data, aes(x = Streams)) +
  geom_histogram(binwidth = 10000, fill = "blue", color = "hotpink") +
  labs(title = "Histogram of Streams",
       x = "Streams",
       y = "Frequency")

# Plot a quantile-quantile (Q-Q) plot
qqnorm(train_data$Streams)
qqline(train_data$Streams, col = "red")

# Calculate and print skewness and kurtosis
cat("Skewness:", skewness(train_data$Streams), "\n")
cat("Kurtosis:", kurtosis(train_data$Streams), "\n")

```
##Log streams to normal
```{r}
library(e1071)

# Check the current distribution of the stream data
original_skewness <- skewness(taylor_all_songs$Streams)
cat("Original Skewness:", original_skewness, "\n")

# Log-transform the stream data
taylor_all_songs$log_Streams <- log(taylor_all_songs$Streams)


# Check the distribution of the log-transformed data
log_skewness <- skewness(taylor_all_songs$log_Streams)
cat("Log-Transformed Skewness:", log_skewness, "\n")

# Plot a histogram
ggplot(taylor_all_songs, aes(x = log_Streams)) +
  geom_histogram(binwidth = 10000, fill = "blue", color = "hotpink") +
  labs(title = "Histogram of Streams",
       x = "Streams",
       y = "Frequency")
# Plot a quantile-quantile (Q-Q) plot
qqnorm(train_data$log_Streams)
qqline(train_data$log_Streams, col = "red")

```

##linear regression
```{r}
library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(caret)

# Select relevant columns for the model
selected_features <- c("album_name", "track_number", "track_name", "danceability", "energy", "key", "loudness", "mode", "speechiness", "acousticness", "instrumentalness", "liveness", "valence", "tempo", "time_signature", "duration_ms", "explicit", "key_name", "mode_name", "key_mode", "Streams")

# Create a data frame with selected features and the target variable
model_data <- taylor_all_songs %>%
  select(Streams, all_of(selected_features)) %>%
  na.omit()  # Remove rows with missing values

# Split the dataset into training and testing sets
set.seed(123)
train_index <- createDataPartition(model_data$Streams, p = 0.8, list = FALSE)
train_data <- model_data[train_index, ]
test_data <- model_data[-train_index, ]
# Ensure levels of categorical variables are consistent
categorical_columns <- c("album_name", "track_name", "key_name", "mode_name")
for (col in categorical_columns) {
  levels_train <- levels(train_data[[col]])
  test_data[[col]] <- factor(test_data[[col]], levels = levels_train)
}

train_data$log_Streams <- log(train_data$Streams)
test_data$log_Streams <- log(test_data$Streams)
# Build a linear regression model
linear_model <- lm(Streams ~ energy + loudness + track_number + speechiness , data = train_data)
# Make predictions on the test set
predictions <- predict(linear_model, newdata = test_data)

# Evaluate the model
rmse <- sqrt(mean((predictions - test_data$Streams)^2))
cat("Root Mean Squared Error (RMSE):", rmse, "\n")

# Visualize actual vs. predicted values
ggplot() +
  geom_point(aes(x = test_data$Streams, y = predictions), color = "blue") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
  labs(title = "Actual vs. Predicted Streams",
       x = "Actual Streams",
       y = "Predicted Streams")

# Display the summary of the linear model
summary(linear_model)



```
##Track number ANOVA + Tukey
```{r}
# Convert track number to factor
train_data$track_number <- as.factor(train_data$track_number)

# Perform ANOVA
anova_result <- aov(Streams ~ track_number, data = train_data)
print(summary(anova_result))

# Perform post-hoc tests
tukey_results <- TukeyHSD(anova_result)
print(tukey_results)

```
##Linear regression after log streams
```{r}
# Remove rows with missing or infinite values in log_Streams
train_data <- train_data[!is.na(train_data$log_Streams) & is.finite(train_data$log_Streams), ]
# Convert track_number to numeric if it's stored as a factor
train_data$track_number <- as.numeric(as.character(train_data$track_number))

# Build a linear regression model
linear_model <- lm(log_Streams ~ energy + loudness + track_number + speechiness, data = train_data)

# Make predictions on the test set
predictions <- predict(linear_model, newdata = test_data)

# Evaluate the model
rmse <- sqrt(mean((predictions - log(test_data$Streams))^2))
cat("Root Mean Squared Error (RMSE):", rmse, "\n")

# Visualize actual vs. predicted values
ggplot() +
  geom_point(aes(x = log(test_data$Streams), y = predictions), color = "blue") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
  labs(title = "Actual vs. Predicted Streams",
       x = "Actual Log-Transformed Streams",
       y = "Predicted Log-Transformed Streams")

# Display the summary of the linear model
summary(linear_model)


```
```{r}
# Convert track number to factor
train_data$track_number <- as.factor(train_data$track_number)

# Perform ANOVA
anova_result <- aov(log_Streams ~ track_number, data = train_data)
print(summary(anova_result))

# Perform post-hoc tests
tukey_results <- TukeyHSD(anova_result)
print(tukey_results)

```




```{r}
# Check if the "Streams" variable is normally distributed in the training set
shapiro_test_result <- shapiro.test(train_data$Streams)

# Print the result of the Shapiro-Wilk test
cat("Shapiro-Wilk test p-value:", shapiro_test_result$p.value, "\n")

# Interpret the result
if (shapiro_test_result$p.value < 0.05) {
  cat("The data is not normally distributed.\n")
} else {
  cat("The data appears to be normally distributed.\n")
}

```

##Separating by albums
```{r}
# Get unique album names
unique_albums <- unique(taylor_all_songs$album_name)

# Loop through each album and create a dataset in the environment
for (album in unique_albums) {
  album_data <- taylor_all_songs %>%
    filter(album_name == album)
  
  # Create a variable in the environment with the album name
  assign(paste0("album_", gsub(" ", "_", album)), album_data)
}

# List all datasets in the environment
ls(pattern = "album_")

```

```{r}
# Plot the number of streams for each song in each album
ggplot(taylor_all_songs, aes(x = reorder(track_name, Streams), y = Streams, fill = album_name)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Number of Streams for Each Song in Each Album",
       x = "Song",
       y = "Number of Streams") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
# Get unique album names
unique_albums <- unique(taylor_all_songs$album_name)

# Define your desired colors for each album
album_colors <- c("Red" = "red", "Red (Taylor's Version)" = "firebrick", "1989" = "skyblue", "1989 (Taylor's Version)" = "royalblue", "Fearless" = "yellow", "Fearless (Taylor's Version)" = "gold", "Speak Now" = "violet", "Speak Now (Taylor's Version)" = "purple" , "Lover" = "hotpink", "Folklore" = "grey", "reputation" = "black", "evermore" = "chocolate", "Taylor Swift" = "lightgreen", "Midnights" = "navy", "Beautiful Eyes" = "orange")

# Create a separate graph for each album with a custom color
for (i in seq_along(unique_albums)) {
  album <- unique_albums[i]
  album_data <- taylor_all_songs %>%
    filter(album_name == album)
  
  # Get the color for the current album
  color <- album_colors[album]
  
  # Plot the number of streams for each song in the album
  plot <- ggplot(album_data, aes(x = reorder(track_name, Streams), y = Streams, fill = album)) +
    geom_bar(stat = "identity") +
    labs(title = paste("Number of Streams for Each Song in", album),
         x = "Song",
         y = "Number of Streams") +
    scale_fill_manual(values = color) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  # Display the plot
  print(plot)
}


```
```{r}
# Create a new variable indicating the version
taylor_all_songs$version <- ifelse(grepl("Taylor's Version", taylor_all_songs$album_name), "Taylor's Version", "")

# Plot the number of streams for each song by version
ggplot(taylor_all_songs, aes(x = reorder(track_name, Streams), y = Streams, fill = version)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Number of Streams for Each Song by Version",
       x = "Song",
       y = "Number of Streams",
       fill = "Version") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

##logistic regression


```{r}
library(dplyr)
library(caret)
library(car)

# Convert categorical variables to factors
taylor_all_songs$album_name <- as.factor(taylor_all_songs$album_name)
taylor_all_songs$track_name <- as.factor(taylor_all_songs$track_name)

# Create a binary outcome variable
taylor_all_songs$binary_streams <- ifelse(taylor_all_songs$Streams > median(taylor_all_songs$Streams), 1, 0)

# Select relevant features
selected_features <- c("album_name", "track_number", "danceability", "energy", "key", "loudness", "mode", "speechiness", "acousticness", "instrumentalness", "liveness", "valence", "tempo", "time_signature", "duration_ms", "explicit", "binary_streams")

# Create the model data
model_data <- taylor_all_songs %>%
  select(all_of(selected_features)) %>%
  na.omit()  # Remove rows with missing values

# Split the dataset into training and testing sets
set.seed(123)
train_index <- createDataPartition(model_data$binary_streams, p = 0.8, list = FALSE)
train_data <- model_data[train_index, ]
test_data <- model_data[-train_index, ]

# Check for multicollinearity
vif_values <- car::vif(lm(binary_streams ~ ., data = train_data))
print("VIF values:")
print(vif_values)

# Build a logistic regression model
logistic_model <- glm(binary_streams ~ ., data = train_data, family = "binomial")

# Make predictions on the test set
predictions <- predict(logistic_model, newdata = test_data, type = "response")

# Convert predicted probabilities to binary predictions (0 or 1)
binary_predictions <- ifelse(predictions > 0.5, 1, 0)

# Evaluate the model
confusion_matrix <- table(test_data$binary_streams, binary_predictions)
cat("Confusion Matrix:\n", confusion_matrix, "\n")

# Calculate accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")

# Display the summary of the logistic regression model
print("Logistic Regression Model Summary:")
print(summary(logistic_model))

```

```{r}
library(pROC)

# Create a ROC curve and calculate AUC
roc_curve <- roc(test_data$binary_streams, predictions)
auc_value <- auc(roc_curve)

# Plot the ROC curve
plot(roc_curve, main = "ROC Curve for Logistic Regression",
     col = "blue", lwd = 2, cex.main = 1.2,
     col.main = "darkred", lty = 2)

# Add AUC value to the plot
text(0.8, 0.2, paste("AUC =", round(auc_value, 3)),
     col = "darkred", cex = 1.2)

# Add diagonal reference line for a random classifier
abline(a = 0, b = 1, lty = 3, col = "gray")

# Add legend
legend("bottomright", legend = c("Logistic Regression", "Random Classifier"),
       col = c("blue", "gray"), lwd = c(2, 1), lty = c(1, 3))

# Display the plot

```
##Decision Tree
```{r}
library(rpart)
library(rpart.plot)
library(caret)
set.seed(123)

# Split the data into training and testing sets (70% training, 30% testing)
train_index <- createDataPartition(taylor_all_songs$Streams, p = 0.7, list = FALSE)
train_data <- taylor_all_songs[train_index, ]
train_data <- subset(train_data, select = -c(lyrics, album_name, artist, featuring, key_mode, track_name, log_Streams, binary_streams))
test_data <- taylor_all_songs[-train_index, ]

# Define the formula for the decision tree model
formula <- Streams ~. 

# Train the decision tree model
decision_tree <- rpart(formula, data = train_data)

# Plot the decision tree
rpart.plot(decision_tree, main = "Decision Tree for Predicting Streams")

# Make predictions on the testing data
predictions <- predict(decision_tree, test_data, type = "vector")

# Evaluate the model's performance
accuracy <- mean((predictions - test_data$Streams)^2)
print(paste("Mean squared error:", accuracy))

```
```{r}
# Split the data into training and testing sets (70% training, 30% testing)
train_index <- createDataPartition(taylor_all_songs$Streams, p = 0.7, list = FALSE)
train_data <- taylor_all_songs[train_index, ]
train_data <- subset(train_data, select = -c(lyrics, album_name, artist, featuring, key_mode, track_name, binary_streams))
test_data <- taylor_all_songs[-train_index, ]

# Define the formula for the decision tree model
formula <- Streams ~ duration_ms + tempo + track_number + energy + loudness + instrumentalness + speechiness + key_name + valence + danceability 

# Train the decision tree model
decision_tree <- rpart(formula, data = train_data)

# Plot the decision tree
rpart.plot(decision_tree, main = "Decision Tree for Predicting Streams")

# Make predictions on the testing data
predictions <- predict(decision_tree, test_data, type = "vector")

# Evaluate the model's performance
accuracy <- mean((predictions - test_data$Streams)^2)
print(paste("Mean squared error:", accuracy))
```
##Decision Tree #3
```{r}
# Split the data into training and testing sets (70% training, 30% testing)
train_index <- createDataPartition(taylor_all_songs$Streams, p = 0.7, list = FALSE)
train_data <- taylor_all_songs[train_index, ]
train_data <- subset(train_data, select = -c(lyrics, artist, featuring, key_mode, track_name, binary_streams))
test_data <- taylor_all_songs[-train_index, ]

# Define the formula for the decision tree model
formula <- Streams ~ album_name + track_number + speechiness + loudness + energy

# Train the decision tree model
decision_tree <- rpart(formula, data = train_data)

# Plot the decision tree
rpart.plot(decision_tree, main = "Decision Tree for Predicting Streams")

# Make predictions on the testing data
predictions <- predict(decision_tree, test_data, type = "vector")

# Evaluate the model's performance
accuracy <- mean((predictions - test_data$Streams)^2)
print(paste("Mean squared error:", accuracy))
```

